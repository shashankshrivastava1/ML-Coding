{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gO5Z0qErNuOt"
   },
   "source": [
    "# Self Attention in Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HedntyUvLrBo"
   },
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xtKbaWhFJui3"
   },
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=QCJQG4DuHT0&list=PLTl9hO2Oobd97qfWC40gOSU8C0iu0m2l4\n",
    "import numpy as np\n",
    "import math\n",
    "#length of input sequence\n",
    "#dimension of d_k and d_v 8\n",
    "L, d_k, d_v = 4, 8, 8\n",
    "q = np.random.randn(L, d_k) #(4,8)\n",
    "k = np.random.randn(L, d_k) #(4,8)\n",
    "v = np.random.randn(L, d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09JpvuNJ2sZC",
    "outputId": "30d2c627-8647-44e0-aa92-c9e53e3b7843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.18366517  0.69549388  0.28884603  1.88644768  0.356903    0.39637446\n",
      "   1.18332284 -1.58432176]\n",
      " [ 0.45665325  0.74760165 -1.64697687  0.50174414  0.96491998 -0.05649554\n",
      "   1.27325481  0.99872008]\n",
      " [ 0.73219883 -1.1298786  -1.47287961 -0.75663372  0.67867084 -0.12142817\n",
      "   0.67622107  1.43914014]\n",
      " [-0.08864795 -0.32775726  0.43245463 -1.37071227  0.14828554 -0.40827039\n",
      "   0.18127552  0.28698922]]\n",
      "K\n",
      " [[-0.12816748  0.21190403 -0.44249429 -0.13868744  1.42614063 -0.52737663\n",
      "   0.43228756  0.18449538]\n",
      " [-1.73838804 -0.45762746 -0.84376157 -0.05844661  0.00398864  0.86225838\n",
      "  -0.4556103   1.06896442]\n",
      " [ 0.27108615  1.41199393  0.46256588 -0.77860606 -0.21756045  1.15999105\n",
      "   0.1461041   1.43479781]\n",
      " [-1.18038042 -1.83654413  1.1959073   0.93188211 -0.16055269 -0.03169963\n",
      "   0.41339721  0.26344204]]\n",
      "V\n",
      " [[-0.14600147  0.19098749 -0.52006742 -0.05113114  0.28067984  1.13968417\n",
      "   0.29878616  0.67347476]\n",
      " [ 0.06907276 -1.2488427  -0.07867611  0.83387608 -2.40047255 -0.13323873\n",
      "  -0.90461205 -0.73292915]\n",
      " [-0.16592726 -1.524926    0.61945438 -0.42440031  0.26770069 -0.02320381\n",
      "   0.1071973  -1.96950857]\n",
      " [ 0.40209635  0.64090491 -1.08064203 -1.47329574 -0.81535135  0.06387228\n",
      "   1.01493538  2.53451224]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV6txskBLwjh"
   },
   "source": [
    "## Self Attention\n",
    "\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7GePHKk3Mh0",
    "outputId": "7dae7f5e-4715-4fd4-fbfd-7c0815e7d39e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25358968, -2.88104898, -2.02151729,  0.6112187 ],\n",
       "       [ 2.89966145,  0.66699015,  1.37043142, -2.77775803],\n",
       "       [ 2.0131616 ,  1.65950051,  0.38608924, -0.70215742],\n",
       "       [ 0.4987502 , -0.1079327 ,  0.7128667 ,  0.08609056]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q, k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odK76OoI3nL2",
    "outputId": "69b50cdb-9a41-45ae-bfd2-619228af1ef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7725460876338028, 0.6963076537474191, 2.440736333874628)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why we need sqrt(d_k) in denominator\n",
    "q.var(), k.var(), np.matmul(q, k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ps6AY1Q3tRI",
    "outputId": "3b9ac3c8-70b8-47bd-e868-e7d6fd26d270"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7725460876338028, 0.6963076537474191, 0.30509204173432847)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "q.var(), k.var(), scaled.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypO9IK1PL3cJ"
   },
   "source": [
    "Notice the reduction in variance of the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVHAJR4N4VQX",
    "outputId": "52b06cf8-0381-453c-b576-0bd8de9a38b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08965749, -1.01860463, -0.71471429,  0.21609844],\n",
       "       [ 1.02518514,  0.23581663,  0.48452067, -0.98208577],\n",
       "       [ 0.71176011,  0.58672203,  0.13650316, -0.24825014],\n",
       "       [ 0.17633482, -0.03815997,  0.25203644,  0.03043761]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dmz4v-RmMAaj"
   },
   "source": [
    "## Masking\n",
    "\n",
    "- This is to ensure words don't get context from words generated in the future. \n",
    "- Not required in the encoders, but required int he decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://numpy.org/doc/stable/reference/generated/numpy.tril.html\n",
    "# import numpy as np\n",
    "# np.tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8N3OhSLILfG",
    "outputId": "2c63a444-066c-44b2-abe5-242dd989f311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones( (L, L) ))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hIV9K3Yn6s1V"
   },
   "outputs": [],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LK5V_T3W6vpX",
    "outputId": "bb4160a1-a011-4850-e403-9cb252572c66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNH1VgEf7xTa",
    "outputId": "4211c411-0356-4e39-8388-d39b0c1d0920"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08965749,        -inf,        -inf,        -inf],\n",
       "       [ 1.02518514,  0.23581663,        -inf,        -inf],\n",
       "       [ 0.71176011,  0.58672203,  0.13650316,        -inf],\n",
       "       [ 0.17633482, -0.03815997,  0.25203644,  0.03043761]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMTAXjooN9eZ"
   },
   "source": [
    "## Softmax\n",
    "\n",
    "$$\n",
    "\\text{softmax} = \\frac{e^{x_i}}{\\sum_j e^x_j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2R4gdRqj8W4Y"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]\n",
      " [15]\n",
      " [18]]\n",
      "[ 6 15 24]\n",
      "[ 6 15 24]\n",
      "[12 15 18]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "#bradcasting\n",
    "ar = np.array = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "\n",
    "k = np.sum(ar,axis =1)\n",
    "print(np.sum(ar,axis=0)\n",
    "print(np.sum(ar,axis=1))\n",
    "print(np.sum(ar,axis=-1))\n",
    "print(np.sum(ar,axis=-2))\n",
    "# print(k)\n",
    "# print(ar/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_new(x):\n",
    "    exp = np.exp(x)\n",
    "    return exp / np.sum(exp,axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "K5eg2zPy41sP"
   },
   "outputs": [],
   "source": [
    "attention = softmax_new(scaled + mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.68769572, 0.31230428, 0.        , 0.        ],\n",
       "       [0.40899401, 0.3609222 , 0.23008379, 0.        ],\n",
       "       [0.26667831, 0.2151958 , 0.28765008, 0.23047581]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sauNmfl-1TB",
    "outputId": "46b22beb-9034-4c7c-8d56-04209d2581c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 4), (4, 8))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape,v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAy37go56LZo",
    "outputId": "78d97fa1-e0b3-4c1d-8294-bf0fdb77f199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.dot(attention, v)\n",
    "new_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCP2aZOU9VrT",
    "outputId": "e1fe2137-cd95-4a4b-fa1a-3ec21c38104c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14600147,  0.19098749, -0.52006742, -0.05113114,  0.28067984,\n",
       "         1.13968417,  0.29878616,  0.67347476],\n",
       "       [ 0.06907276, -1.2488427 , -0.07867611,  0.83387608, -2.40047255,\n",
       "        -0.13323873, -0.90461205, -0.73292915],\n",
       "       [-0.16592726, -1.524926  ,  0.61945438, -0.42440031,  0.26770069,\n",
       "        -0.02320381,  0.1071973 , -1.96950857],\n",
       "       [ 0.40209635,  0.64090491, -1.08064203, -1.47329574, -0.81535135,\n",
       "         0.06387228,  1.01493538,  2.53451224]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_JndWelLDNW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSiJuBQELFHT"
   },
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvTnmdcB_jdq"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "  d_k = q.shape[-1]\n",
    "  scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "  if mask is not None:\n",
    "    scaled = scaled + mask\n",
    "  attention = softmax(scaled)\n",
    "  out = np.matmul(attention, v)\n",
    "  return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSxLkZdiSLMT",
    "outputId": "ca70508d-fb6e-4eec-acb6-7a89a60dffa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.11672673 -2.54870451 -1.44065948  0.93661829  1.36278968  1.04252277\n",
      "  -0.01310938 -1.3163937 ]\n",
      " [ 0.26721599 -0.90218255  0.07417847 -0.10430246  0.52684253 -0.07081531\n",
      "  -0.60511725 -0.55225527]\n",
      " [-0.93297509  0.28724456  1.37184579  0.41589874  0.34981245 -0.24753755\n",
      "  -1.24497125  0.05044148]\n",
      " [-0.11414585 -0.01545749 -0.58376828 -0.40193907  0.93931836 -1.94334363\n",
      "  -0.34770465  1.50103406]]\n",
      "K\n",
      " [[ 1.1226585  -0.85645535  0.54315044  1.36560451  0.52539476 -0.94502504\n",
      "  -0.48444661  0.46268014]\n",
      " [-0.53713766 -1.16937329 -0.57988617  0.92713577 -0.85995607 -0.40352635\n",
      "   0.26555146 -1.83159914]\n",
      " [-2.06994435 -0.09514715 -1.64928361 -0.17375184  0.13146819 -1.76335363\n",
      "   1.56568846  0.69751826]\n",
      " [ 0.32910684 -0.1939204  -0.80444134  0.78816869  0.35599408  0.28309835\n",
      "  -0.25970963  1.49744622]]\n",
      "V\n",
      " [[-0.00368231  1.43739233 -0.59614565 -1.23171219  1.12030717 -0.98620738\n",
      "  -0.15461465 -1.03106383]\n",
      " [ 0.85585446 -1.79878344  0.67321704  0.05607552 -0.15542661 -1.41264124\n",
      "  -0.40136933 -1.17626611]\n",
      " [ 0.50465335  2.28693419  0.67128338  0.2506863   1.78802234  0.14775751\n",
      "  -0.11405725  0.88026286]\n",
      " [-0.68069105  0.68385101  0.17994557 -1.68013201  0.91543969 -0.19108312\n",
      "   0.03160471  1.40527326]]\n",
      "New V\n",
      " [[-0.00368231  1.43739233 -0.59614565 -1.23171219  1.12030717 -0.98620738\n",
      "  -0.15461465 -1.03106383]\n",
      " [ 0.41440401 -0.13671232  0.02128364 -0.60532081  0.49977893 -1.1936286\n",
      "  -0.27463831 -1.10169151]\n",
      " [ 0.32673907  0.72121642 -0.00947672 -0.59897862  0.90155754 -0.88535361\n",
      "  -0.21384855 -0.7053796 ]\n",
      " [ 0.18700384  1.67754576  0.33105314 -0.41795742  1.4258469  -0.18788199\n",
      "  -0.10285145  0.54683565]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.51359112 0.48640888 0.         0.        ]\n",
      " [0.53753304 0.27144826 0.1910187  0.        ]\n",
      " [0.19293995 0.03256643 0.57960627 0.19488734]]\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HtQQtB2LJus"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
